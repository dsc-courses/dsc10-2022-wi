{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7: Confidence Intervals, the Normal Distribution, and the Central Limit Theorem\n",
    "\n",
    "## Due Saturday, March 5th at 11:59PM\n",
    "\n",
    "Welcome to Homework 7! This week, we will cover confidence intervals, normal distributions, and the Central Limit Theorem. You can find additional help on these topics in the following readings:\n",
    "\n",
    "* [Note 24](https://notes.dsc10.com/06-estimation/2_confidence_intervals.html): Confidence Intervals\n",
    "* [Note 25](https://notes.dsc10.com/06-estimation/3_ht_using_intervals.html): Hypothesis Tests for Parameters using Confidence Intervals\n",
    "* [CIT 14.2](https://www.inferentialthinking.com/chapters/14/2/Variability.html): Variability, Standard Deviation, Standard Units, Chebyshev's Bounds\n",
    "* [CIT 14.3](https://www.inferentialthinking.com/chapters/14/3/SD_and_the_Normal_Curve.html): The Standard Deviation (SD) and the Normal Curve \n",
    "* [CIT 14.4](https://www.inferentialthinking.com/chapters/14/4/Central_Limit_Theorem.html): The Central Limit Theorem\n",
    "* [CIT 14.5](https://www.inferentialthinking.com/chapters/14/5/Variability_of_the_Sample_Mean.html): The Variability of the Sample Mean\n",
    "* [CIT 14.6](https://inferentialthinking.com/chapters/14/6/Choosing_a_Sample_Size.html): Choosing a Sample Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "This assignment is due Saturday, March 5th at 11:59PM. You are given six slip days thoughout the quarter to extend deadlines. See the syllabus for more details. With the exception of using slip days, late work will not be accepted unless you have made special arrangements with your instructor.\n",
    "\n",
    "**Important**: For homeworks, the `otter` tests don't usually tell you that your answer is correct. More often, they help catch careless mistakes. It's up to you to ensure that your answer is correct. If you're not sure, ask someone (not for the answer, but for some guidance about your approach). These are great questions for office hours (see the schedule on the [Calendar](https://dsc10.com/calendar)) or Campuswire. Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell, but do make sure to run it\n",
    "import babypandas as bpd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import otter\n",
    "grader = otter.Notebook()\n",
    "\n",
    "from IPython.display import IFrame\n",
    "def show_clt_slides():\n",
    "    src = \"https://docs.google.com/presentation/d/e/2PACX-1vTcJd3U1H1KoXqBFcWGKFUPjZbeW4oiNZZLCFY8jqvSDsl4L1rRTg7980nPs1TGCAecYKUZxH5MZIBh/embed?start=false&loop=false&delayms=3000\"\n",
    "    width = 700\n",
    "    height = 370\n",
    "    display(IFrame(src, width, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Comparing UCSD Writing Courses ‚úçÔ∏è\n",
    "Suppose it's application season and you're a current high school senior looking to apply to UCSD for data science. (Did you know that UCSD was the the [second-most applied to college in the US](https://ucsdnews.ucsd.edu/pressrelease/uc-san-diego-admits-record-52946-first-year-and-transfer-students) for Fall 2021?) Say you're not too good at writing and want to strategically analyze the writing courses of each college, to figure out where you have the best shot at getting a decent grade. Luckily, you're made aware of UCSD's [Course and Professor Evalutions (CAPE)](https://cape.ucsd.edu/), which keeps data on the average grade received in each course for each quarter. \n",
    "\n",
    "In the DataFrame below, each row corresponds to a particular quarter's offering of a college writing course, except for Muir's writing courses, for which data is unavailable. We have information on the name of each course, the average study hours per week for the quarter, and the average grade for the quarter (on a 4.0 GPA scale). Now it's time to analyze and figure out whether the writing course rumors are true, or if people just like complaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writing = bpd.read_csv('data/writing_courses_ucsd.csv', index_col=0)\n",
    "writing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.** Let's start by determining the mean study hours and mean grade for each course. Create a table called `course_means`, indexed by `course`, with columns `'Study Hrs/wk'` and `'grades'`, showing the mean study hours and mean grade for each course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "course_means = ...\n",
    "course_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2.** Marshall's writing course, `'DOC'`, seems to have a pretty high mean grade based on the data in our sample, but this sample doesn't include all course offerings. Produce 1,000 bootstrapped estimates for the mean grade of all offerings of `'DOC'`. Store the estimates in the `doc_averages` array. \n",
    "\n",
    "Then, use the `doc_averages` array to calculate an approximate 99% confidence interval for the true mean grade. Assign the corresponding bounds to `lower_bound` and `upper_bound`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_averages = ...\n",
    "\n",
    "...\n",
    "\n",
    "# Display the estimates in a histogram.\n",
    "bpd.DataFrame().assign(Estimated_Average_Grades=doc_averages).plot(kind='hist', density=True, ec='w', figsize=(10, 5));\n",
    "\n",
    "lower_bound = ...\n",
    "upper_bound = ...\n",
    "\n",
    "# Don't change the line below (though you will need to copy and change it in 1.3)\n",
    "\"A 99% confidence interval for {} is [{}, {}]\".format(\"DOC\", lower_bound, upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3.** You want to create a similar histogram for each of the other courses, and also calculate the corresponding confidence intervals. Repeating the process above 4 times would be time-consuming. Create a function called `ci_and_hist`, which takes in a course name as its input, **plots the histogram** for 1,000 bootstrapped estimates for the mean grade **and returns** a string describing the approximate 99% confidence interval for the course's mean grade, formatted in the same way as the string displayed for `'DOC'` in Question 1.2. Start with the code from 1.2 and generalize it to work for any course.\n",
    "\n",
    "**_Note_:** Make sure your function both plots a histogram and **returns** a string. For example, `ci_and_hist('MMW')` should return a string that starts with `'A 99% confidence interval for MMW is'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ci_and_hist(course_name):\n",
    "    ...\n",
    "    \n",
    "# Example call to the function. Don't change the lines below\n",
    "test_var = ci_and_hist('MMW')\n",
    "print(test_var)\n",
    "other_var = ci_and_hist('WCWP')\n",
    "print(other_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4.** Your friend claims that Warren's writing course, `'WCWP'`, is actually not as easy as everyone says. She claims that since our CAPE data is only a sample of the full population of course offerings, the actual mean grade for `'WCWP'`  could be 2.95. Run the cell below to use the `ci_and_hist` function you defined above to calculate an approximate 99% confidence interval for the mean grade in `'WCWP'`. Do you reject her hypothesis at the 0.01 significance level? Assign 1, 2, 3, or 4 to `q1_4`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. No, because the confidence interval includes 2.95.\n",
    "2. No, because the confidence interval doesn't include 2.95.\n",
    "3. Yes, because the confidence interval includes 2.95.\n",
    "4. Yes, because the confidence interval doesn't include 2.95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_and_hist(\"WCWP\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_4 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Testing the Central Limit Theorem: Coin Flips and Midterm Scores üíØ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Central Limit Theorem tells us that the probability distribution of the sum or mean of a large random sample drawn with replacement will be roughly normal, *regardless of the distribution of the population from which the sample is drawn*.\n",
    "\n",
    "That's a pretty big claim, but the theorem doesn't stop there. It further states that, if we're using the mean as our statistic, the standard deviation of this normal distribution is given by $$\\text{SD of Distribution of Possible Sample Means} = \\frac{\\text{Population SD}}{\\sqrt{\\text{sample size}}}$$\n",
    "\n",
    " In other words, suppose we start with *any distribution* that has standard deviation $\\sigma$, take a sample of size $n$ (where $n$ is a large number) from that distribution with replacement, and compute the mean of that sample. If we repeat this procedure many times, then those sample means will have a normal distribution with standard deviation $\\frac{\\sigma}{\\sqrt{n}}$.\n",
    "\n",
    "That's an even bigger claim than the first one! The proof of the theorem is beyond the scope of this class.\n",
    "\n",
    "Run the cell below to see a short presentation that describes the CLT at a high level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_clt_slides()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will be exploring some data to see the CLT in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1.** The CLT only applies when sample sizes are \"sufficiently large.\" This isn't a very precise statement. Is 10 large?  How about 50?  The truth is that it depends both on the original population distribution and just how \"normal\" you want the result to look. Let's use a simulation to get a feel for how the distribution of the sample mean changes as sample size goes up.\n",
    "\n",
    "Consider a coin flip. If we say heads is $1$ and tails is $0$, then there's a 50% chance of getting a 1 and a 50% chance of getting a 0, which is definitely not a normal distribution.  The average of several coin tosses is equal to the proportion of heads in those coin tosses, so the CLT should apply if we compute the sample proportion of heads many times.\n",
    "\n",
    "Write a function called `simulate_sample_n` that takes in a sample size `n`. It should repeat, 5000 times, the process of:\n",
    "- simulating `n` flips of a fair coin, and\n",
    "- counting the proportion of flips that were heads\n",
    "\n",
    "`simulate_sample_n` should return an array that contains 5000 sample proportions, using the process outlined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_sample_n(n):\n",
    "    ...\n",
    "simulate_sample_n(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "The code below will use the function you just defined to plot the empirical distribution of the sample mean for several different sample sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bins = np.arange(-0.01, 1.05, 0.02)\n",
    "\n",
    "for sample_size in np.array([2, 5, 10, 20, 50, 100, 200, 400]):\n",
    "    bpd.DataFrame().assign(**{'Sample_Size:{}'.format(sample_size) : simulate_sample_n(sample_size)}) \\\n",
    "                   .plot(kind='hist', density=True, ec='w', bins=bins, \n",
    "                         title=f'Sample Size {sample_size}', legend=None, figsize=(5, 3));\n",
    "    plt.xlim(-0.01, 1.05)\n",
    "    plt.ylim(0, 25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that even the means of samples of 10 items follow a roughly bell-shaped distribution.  A sample of 50 items looks quite bell-shaped. Note also that as sample sizes increased, the distributions of sample proportions became narrower and taller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will test the second claim of the CLT: That the SD of the sample mean is the SD of the original distribution, divided by the square root of the sample size.\n",
    "\n",
    "$$\\text{SD of Distribution of Possible Sample Means} = \\frac{\\text{Population SD}}{\\sqrt{\\text{sample size}}}$$\n",
    "\n",
    "Below, we will read in the scores of this quarter's Midterm Exam (which we have modified slightly for anonymity). We'll treat this DataFrame as our population, and we'll take samples directly from it. We've computed the standard deviation of the midterm scores for you; you will need to use this at some point in the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midterm = bpd.read_csv('data/wi22_midterm_scores.csv')\n",
    "midterm_std = np.std(midterm.get('Score'))\n",
    "midterm_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.** Write a function called `predict_sd` that takes in a sample size `n`. It returns the predicted standard deviation (according to the CLT) of the sample mean's distribution, for samples of size `n` taken from the midterm data.\n",
    "\n",
    "**_Hint:_** Use `midterm_std`, and **do not** use `simulate_sample_n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sd(n):\n",
    "    ...\n",
    "\n",
    "predict_sd(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.** Write a function called `empirical_sd` that takes a sample size `n` as its argument. The function should simulate drawing 1000 samples of size `n` from the midterm scores dataset, with replacement, and it should return the **standard deviation of the distribution of the means** of those 1000 samples.\n",
    "\n",
    "**_Hint:_** This function will be similar to the `simulate_sample_n` function you wrote earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_sd(n): \n",
    "    sample_means = np.array([])\n",
    "    ...\n",
    "    return np.std(sample_means)\n",
    "empirical_sd(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will plot the predicted SDs (computed by your `predict_sd` function) and empirical SDs (computed by your `empirical_sd` function) for the flight delay data for various sample sizes. It may take a few moments to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_df = bpd.DataFrame().assign(Sample_Size = np.arange(1, 101, 10))\n",
    "predicted = sd_df.get('Sample_Size').apply(predict_sd)\n",
    "empirical = sd_df.get('Sample_Size').apply(empirical_sd)\n",
    "sd_df = sd_df.assign(Predicted_SD = predicted, Empirical_SD = empirical)\n",
    "ax = sd_df.plot(kind='scatter',x='Sample_Size', y='Empirical_SD',label = 'Empirical_SD', color = 'green', alpha=.7, s=300, figsize=(10, 5));\n",
    "ax = sd_df.plot(kind='scatter',x='Sample_Size', y='Predicted_SD',label = 'Predicted_SD', color = 'orange', alpha=.7, s=300, ax=ax)\n",
    "ax.set_ylabel('Standard Deviation');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the CLT is pretty accurate!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. UCSD's Housing Crisis üè†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The article we linked in Question 1](https://ucsdnews.ucsd.edu/pressrelease/uc-san-diego-admits-record-52946-first-year-and-transfer-students) notes that UCSD admitted a record-breaking number of students this application season, despite the pandemic. According to [data provided by the Registrar's Office](https://blink.ucsd.edu/instructors/courses/enrollment/week3.html), there are now 40,873 students at UCSD. \n",
    "\n",
    "Also during the pandemic, UCSD's Housing Dining Hospitality (HDH) announced their decision to remove triple occupancy dorm rooms and replace two-year housing guarantees with a priority system. As a result of the new housing policy, many students were left scrambling to secure housing for the 2021-22 school year. In response, UCSD\n",
    "- directed students to an off-campus housing website,\n",
    "- hosted an off-campus housing webinar, and\n",
    "- offered an option for students to live in local hotels at a discounted rate.\n",
    "\n",
    "A data scientist at UCSD wanted to see if students were actually satisfied with the solutions UCSD provided. She polled a uniform random sample of all UCSD students, and determined that 210 of the 700 sampled students found the solutions that UCSD provided to be satisfactory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell, but don't change it.\n",
    "survey = bpd.DataFrame().assign(\n",
    "    Opinion=np.array([\"Satisfactory\", \"Unsatisfactory\"]),\n",
    "    Count=np.array([210,   490]))\n",
    "sample_size = survey.get(\"Count\").sum()\n",
    "survey_results = survey.assign(\n",
    "    Proportion=survey.get(\"Count\") / sample_size)\n",
    "survey_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, she used 1000 bootstrap resamples to compute a confidence interval for the proportion of all UCSD students who found the solutions satisfactory.  Run the next cell to see the empirical distribution of `'Satisfactory'` proportions in the 1000 resamples.\n",
    "\n",
    "Note that we're using `np.random.multinomial` to do the resampling here, since each element of the resample is either 0 (unsatisfactory) or 1 (satisfactory) with known probabilities. This accomplishes the same thing as using `.sample(, replace=True)`, but runs much quicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_proportions = np.array([])\n",
    "for i in np.arange(1000):\n",
    "    resample = np.random.multinomial(sample_size, survey_results.get('Proportion')) / sample_size\n",
    "    boot_proportions = np.append(boot_proportions, resample[0])\n",
    "bpd.DataFrame().assign(boot_proportions = boot_proportions).plot(kind='hist', density=True, ec='w', bins=np.arange(0.15, 0.45, .01), figsize=(10,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall, the Central Limit Theorem says\n",
    "\n",
    "$$\\text{SD of Distribution of Possible Sample Means} = \\frac{\\text{Population SD}}{\\sqrt{\\text{sample size}}}$$\n",
    "\n",
    "Furthermore, in a population whose members are 0 and 1, there is a simple formula for the standard deviation of that population:\n",
    "\n",
    "$$\\text{Population SD} = \\sqrt{(\\text{Proportion of 0s in Population}) \\times (\\text{Proportion of 1s in Population})}$$\n",
    "\n",
    "(Figuring out this formula, starting from the definition of the standard deviation, is a fun exercise for those who enjoy algebra.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.**\n",
    "**Without accessing the data in `boot_proportions` in any way**, compute an approximation of the standard deviation of the array `boot_proportions` and assign it to the variable `approximate_sd`.\n",
    "\n",
    "Instead of using `boot_proportions` directly, use **both** the Central Limit Theorem and the population standard deviation formula above. Since you don't know the true proportions of 0s and 1s in the population, use the proportions in the sample instead (since they're likely to be similar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approximate_sd = ...\n",
    "approximate_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2.** Compute the actual standard deviation of the array `boot_proportions` to verify that your answer to Question 3.1 is approximately correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_sd = ...\n",
    "exact_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3.**\n",
    "**Still without accessing `boot_proportions` in any way**, compute an approximate 95% confidence interval for the proportion of students that would find UCSD's solutions satisfactory. The cell below `grader.check(\"q3_3\")` draws your interval in green below the histogram of `boot_proportions`; use that to verify that your answer looks right.\n",
    "\n",
    "**_Hint:_** In the past, we've used `np.percentile` on the array of bootstrapped estimates to find the bounds for the confidence interval. Now, **we're not allowed to use the bootstrapped distribution**, so we can't do it that way. But we don't need to! The Central Limit Theorem tells us that the distribution of the sample mean is normal with a certain standard deviation. We also know that 95% of the area of the normal distribution falls within a certain number of standard deviations (2) from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_limit = ...\n",
    "upper_limit = ...\n",
    "\n",
    "# Your interval is:\n",
    "[lower_limit, upper_limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to plot your confidence interval.\n",
    "bpd.DataFrame().assign(boot_proportions = boot_proportions).plot(kind='hist', density=True, ec='w', bins=np.arange(0.15, 0.45, 0.01), figsize=(10, 5), alpha=0.65);\n",
    "plt.plot([upper_limit, lower_limit], [0, 0], color='green', linewidth=10, label='Normal CI');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your confidence interval should make it clear that we're pretty confident that relatively few students were satisfied by UCSD's solutions. This makes sense, as the proportion of `'Satisfactory'` opinions in the sample was only 0.30. \n",
    "\n",
    "Just to confirm that this conclusion is accurate, the data scientist decides to redo the survey with a larger sample to estimate the population proportion of `'Satisfactory'` opinions with greater accuracy. She would be happy if the **standard deviation of the sample mean were only 0.005**.  She'll need to take a new sample that's large enough to achieve that. Polling is time-consuming, so the sample also shouldn't be bigger than necessary.\n",
    "\n",
    "Instead of making the conservative assumption that the population standard deviation is 0.5 (the largest possible SD of a 0-1 population), she decides to assume that it's equal to the standard deviation of her first sample. That is,\n",
    "\n",
    "$$\\text{Population SD} \\approx \\sqrt{(\\text{Proportion of 0s in Sample}) \\times (\\text{Proportion of 1s in Sample})}$$\n",
    "\n",
    "Under that assumption, she computes the smallest sample size necessary in order to be confident that the standard deviation of the sample mean is only 0.005."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4.**\n",
    "What sample size did she find? Assign your answer to the variable `new_sample_size`, which should be of type `int`.\n",
    "\n",
    "Use the fact that $$\\text{SD of Distribution of Possible Sample Means} = \\frac{\\text{Population SD}}{\\sqrt{\\text{sample size}}}$$\n",
    "\n",
    "**_Hint:_** When converting to `int`, don't round down!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample_size = ...\n",
    "new_sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5.** Suppose the data scientist wants to be even more precise and take a sample of sufficient size such that the standard deviation of the sample mean distribution is 0.00125. Is it possible for her to do this? Choose the best answer and explanation, then assign `q3_5` to either 1, 2, 3, or 4.\n",
    "1. Yes. She can repeat the sample again until she comes across a sample with a standard deviation of 0.0025.\n",
    "2. Yes. Since the 0.00125 is a quarter of 0.005, the required sample size is a fourth of `new_sample_size`.\n",
    "3. Yes. Since the 0.00125 is a quarter of 0.005, the required sample size is four times `new_sample_size`.\n",
    "3. No, the sample size required to reach that sample mean standard deviation is larger than the number of students at UCSD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_5 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Key Concepts üîë"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1.** How do we standardize a value of 23 if it comes from a dataset where the mean is 55 and the standard deviation is 8? Assign `q4_1` to either 1, 2, 3, or 4.\n",
    "\n",
    "1.\n",
    "$\\dfrac{({55-23})^2}{8}$\n",
    "\n",
    "2.\n",
    "$\\dfrac{55-23}{8}$\n",
    "\n",
    "3.\n",
    "$\\dfrac{23-55}{8}$\n",
    "\n",
    "4.\n",
    "$\\dfrac{{23-55}}{\\sqrt{8}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2.** According to Chebyshev's Inequality, for any dataset, at least half the data falls within how many standard deviations of the mean? Assign the smallest correct answer to `q4_2`.\n",
    "\n",
    "1. 0.87\n",
    "2. 1.28\n",
    "3. 1.42\n",
    "4. 1.83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3.** Assign `q4_3` to a **list** of all statements below that are **always** true.\n",
    "\n",
    "1. If we know the mean and SD of a distribution, we can calculate a 95% confidence interval by stepping out two standard deviations from the mean in either direction.\n",
    "2. An empirical histogram of the sample average of a large random sample drawn with replacement from a population will be roughly normal.\n",
    "3. An empirical histogram of the sample median of a large random sample drawn with replacement from a population will be roughly normal.\n",
    "4. For any distribution, 68% of the data falls within one standard deviation of the mean.\n",
    "5. For any distribution, at least 68% of the data falls within two standard deviations of the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_3 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish Line üèÅ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You are done with Homework 7 ‚Äì the final homework of the quarter! üéâ\n",
    "\n",
    "To submit your assignment:\n",
    "\n",
    "1. Select `Kernel -> Restart & Run All` to ensure that you have executed all cells, including the test cells.\n",
    "2. Read through the notebook to make sure everything is fine and all tests passed.\n",
    "3. Run the cell below to run all tests, and make sure that they all pass.\n",
    "4. Download your notebook using `File -> Download as -> Notebook (.ipynb)`, then upload your notebook to Gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

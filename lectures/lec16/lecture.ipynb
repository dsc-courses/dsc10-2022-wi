{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import babypandas as bpd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 16 ‚Äì Hypothesis Testing, Continued\n",
    "\n",
    "## DSC 10, Winter 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements\n",
    "\n",
    "- The Midterm Project is due **tomorrow at 11:59pm**.\n",
    "    - Check the [Calendar](https://dsc10.com/calendar) for the most up-to-date office hours schedule (we've added a few more over the weekend).\n",
    "- Midterm Exam grades are available on Gradescope.\n",
    "    - **If you didn't do as well as you'd hope, remember that the Midterm Exam is only worth 10% of your overall grade!**\n",
    "- Lab 5 is due on **Thursday 2/17 at 11:59pm**.\n",
    "- Homework 5 will be released on Sunday and will be due on **Saturday 2/19 at 11:59pm**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- Example: Is our coin fair?\n",
    "- Decisions and uncertainty.\n",
    "- Example: Midterm scores.\n",
    "    - p-values.\n",
    "- Example: Jury Panels.\n",
    "    - Total variation distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Is our coin fair?\n",
    "\n",
    "Recall, last class we looked at two pairs of viewpoints, regarding the flips of a coin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### (1) ‚ÄúThis coin is fair.‚Äù OR ‚ÄúNo, it‚Äôs not.‚Äù\n",
    "\n",
    "* Large or small values of the number of heads suggest that the coin is \"not fair\".\n",
    "    - **Test statistic: $| \\text{number of heads} - 200 |$.**\n",
    "    - Large values of the statistic suggest that the coin is \"not fair\".\n",
    "    - If we used the number of heads, then both large values of the statistic **and** small values of the statistic suggest that the coin is \"not fair\", which makes the calculation more complicated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### (2) ‚ÄúThis coin is fair.‚Äù OR ‚ÄúNo, it‚Äôs biased towards heads.‚Äù\n",
    "\n",
    "* Only large values of the number of heads suggest that the coin is \"biased toward heads\".\n",
    "    - **Test statistic: number of heads.**\n",
    "    - Statistic (1) wouldn't work because some large values of statistic (1) lean towards \"biased towards heads\" (when there are many heads), while some don't (when there are many more tails than 200, statistic (1) is also large)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pick a (possibly) biased coin\n",
    "- We'll randomly select the chance that the coin flips heads from the list `[0.4, 0.5, 0.6]`, but we will **not** look at this chance directly.\n",
    "- We'll then flip this coin 400 times and look at the resulting number of heads and tails. \n",
    "    - This is our \"observation\", i.e. it's the equivalent of seeing a jury panel with 8 Black men on it, or seeing 705 plants with purple flowers out of 929.\n",
    "    - This is **not** our simulation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By setting a seed, we ensure that we get the same results every time this cell is run.\n",
    "np.random.seed(42)\n",
    "\n",
    "# Pick a possibly biased coin\n",
    "prob = np.random.choice([0.4, 0.5, 0.6])\n",
    "\n",
    "# Flip this coin 400 times; flips = [Num Heads, Num Tails]\n",
    "flips = np.random.multinomial(400, [prob, 1 - prob])\n",
    "flips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Compute the statistics\n",
    "- Is the coin biased?\n",
    "- Is the coin biased toward heads?\n",
    "- Let's write functions that compute the two relevant statistics (the number of heads, and the distance between the number of heads and 200) given an array of flips.\n",
    "    - Why 200? That's the number of heads we'd expect if we flip a fair coin ($0.5 \\cdot 400 = 200$).\n",
    "    - Instead of the number of heads and 200, we could look at the proportion of heads and 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_heads(arr):\n",
    "    return arr[0]\n",
    "\n",
    "def dist_from_200(arr):\n",
    "    return np.abs(num_heads(arr) - 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads(flips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_from_200(flips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What do these statistics look like for a fair coin?\n",
    "\n",
    "For each pair of viewpoints:\n",
    "- Define the model for a fair coin (done).\n",
    "- Define the test statistic (done).\n",
    "- Run the simulation: flip the coin 400 times, calculate the test statistic, and add it to a `results` array. Repeat this process many, many times.\n",
    "- Plot a histogram of the `results`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### (1) ‚ÄúThis coin is fair.‚Äù OR ‚ÄúNo, it‚Äôs not.‚Äù\n",
    "\n",
    "For this pair of viewpoints, a good test statistic is\n",
    "\n",
    "$$ | \\text{number of heads} - 200 |$$\n",
    "\n",
    "This is calculated by our function `dist_from_200`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [0.5, 0.5]\n",
    "\n",
    "repetitions = 10000\n",
    "results = np.array([])\n",
    "for i in np.arange(repetitions):\n",
    "    coins = np.random.multinomial(400, model)\n",
    "    result = dist_from_200(coins)\n",
    "    results = np.append(results, result)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd.DataFrame().assign(results=results).plot(kind='hist', density=True, bins=np.arange(0, 40, 2), ec='w',\n",
    "                                             figsize=(10, 5));\n",
    "plt.axvline(dist_from_200(flips), color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The distance between the number of heads in our observed sample (236) and 200 is 36, which is much, much larger than a typical distance **under the assumption that the coin is fair**.\n",
    "- As such, the coin is probably not fair, and we side with the viewpoint \"No, it's not fair.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### (2) ‚ÄúThis coin is fair.‚Äù OR ‚ÄúNo, it‚Äôs biased towards heads.‚Äù\n",
    "\n",
    "A good test statistic here is the number of heads, which is calculated by our function `num_heads`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that we can re-use most of our code from above!\n",
    "# The only part that will change is how we calculate our statistic.\n",
    "\n",
    "model = [0.5, 0.5]\n",
    "\n",
    "repetitions = 10000\n",
    "results = np.array([])\n",
    "for i in np.arange(repetitions):\n",
    "    coins = np.random.multinomial(400, model)\n",
    "    result = num_heads(coins)\n",
    "    results = np.append(results, result)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd.DataFrame().assign(results=results).plot(kind='hist', density=True, bins=np.arange(160, 240, 5), ec='w',\n",
    "                                             figsize=(10, 5));\n",
    "plt.axvline(num_heads(flips), color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The number of heads in our observed sample is 236.\n",
    "- Under the assumption that the coin is fair, we essentially never saw 236 or more heads in 400 flips.\n",
    "- As such, the coin is probably not fair, and we side with the viewpoint \"No, it's biased towards heads.\"\n",
    "    - Note that if the vertical red line was somewhere near 160, we'd side with the viewpoint \"This coin is fair.\" since a small number of heads is not evidence in favor of the viewpoint \"No, it's biased towards heads.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Was the coin biased?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What if the coin is only *slightly* biased?\n",
    "\n",
    "Let's suppose our coin flips heads with probability 0.51 and tails with probability 0.49."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(23)\n",
    "prob = 0.51\n",
    "flips = np.random.multinomial(400, [prob, 1-prob])\n",
    "flips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's again simulate the number of heads in 400 flips of a fair coin, 10000 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [0.5, 0.5]\n",
    "repetitions = 10000\n",
    "results = np.array([])\n",
    "for i in np.arange(repetitions):\n",
    "    coins = np.random.multinomial(400, model)\n",
    "    result = num_heads(coins)\n",
    "    results = np.append(results, result)\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "bpd.DataFrame().assign(num_of_heads=results).plot(kind='hist', density=True, ec='w', bins=20, figsize=(10, 5));\n",
    "plt.axvline(num_heads(flips), color='red', label='observed statistic')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Even though this new coin is still biased, the resulting number of heads in our observed sample is not all that atypical according to the model that the coin is fair.\n",
    "    - In other words: the observed number of heads **looks like** it could have come from a fair coin.\n",
    "- As such, given the data we have, we'd still side with the viewpoint that the coin is fair, even though it truly isn't."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discussion Question\n",
    "If the coin were biased towards heads with probability 0.51, how can we change the experiment to detect the bias?\n",
    "\n",
    "|Option|Answer|\n",
    "|---|---|\n",
    "|A.|Increase the number of experiments|\n",
    "|B.|Increase the number of coin flips per experiment|\n",
    "|C.|Find a totally different statistic|\n",
    "|D.|There's no way to detect a bias this small|\n",
    "\n",
    "### To answer, go to [menti.com](https://menti.com) and enter the code 4235 1662."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design the experiment\n",
    "def run_experiments(number_of_flips, number_of_repetitions):\n",
    "    prob = 0.51\n",
    "    flips = np.random.multinomial(number_of_flips, [prob, 1-prob])\n",
    "    model = [0.5, 0.5]\n",
    "\n",
    "    results = np.array([])\n",
    "    for i in np.arange(number_of_repetitions):\n",
    "        coins = np.random.multinomial(number_of_flips, model)\n",
    "        result = num_heads(coins)\n",
    "        results = np.append(results, result)\n",
    "    return results, flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, flips = run_experiments(number_of_flips=40000, number_of_repetitions=10000)\n",
    "\n",
    "bpd.DataFrame().assign(results=results).plot(kind='hist', density=True, ec='w', bins=20, figsize=(10, 5))\n",
    "plt.axvline(num_heads(flips), color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decisions and uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Incomplete information\n",
    "\n",
    "- We try to choose between two views of the world, based on data in a sample.\n",
    "- It's not always clear whether the data are consistent with one view or the other.\n",
    "- Random samples can turn out quite extreme. It is unlikely, but possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Testing hypotheses\n",
    "- A test chooses between two views of how data were generated.\n",
    "- The views are called **hypotheses**.\n",
    "- The test picks the hypothesis that is better supported by the observed data.\n",
    "    - We will formalize this notion now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Null and alternative hypotheses\n",
    "- This method only works if we can simulate data under one of the hypotheses.\n",
    "- **Null hypothesis**: A well-defined probability model about how the data were generated.\n",
    "    - We can simulate data under the assumptions of this model ‚Äì ‚Äúunder the null hypothesis‚Äù.\n",
    "- **Alternative hypothesis**: A different view about the origin of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Test statistics, revisited\n",
    "- Recall, we compute the test statistic on each of our samples in our simulation.\n",
    "- Its goal is to give us information that will help us in determining which hypothesis to side with.\n",
    "- The test statistic evaluated on our observed data is called the **observed statistic**.\n",
    "\n",
    "Questions before choosing the statistic:\n",
    "- What values of the statistic will make us lean towards the null hypothesis?\n",
    "- What values will make us lean towards the alternative?\n",
    "    - The answer should be just ‚Äúhigh‚Äù or just \"low\". \n",
    "    - Try to avoid ‚Äúboth high and low‚Äù: this is why, for example, we used the statistic $| \\text{number of heads} - 200|$ when our alternative hypothesis was \"the coin is not fair.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Empirical distribution of the test statistic\n",
    "- When performing a hypothesis test, we **simulate** the test statistic **under the null hypothesis** and draw a histogram of the simulated values.\n",
    "- This shows us the **empirical distribution of the test statistic under the null hypothesis**.\n",
    "    - It shows all of the likely values of the test statistic.\n",
    "    - It also shows how likely they are, under the assumption that the null hypothesis is true.\n",
    "    - The probabilities are approximate, because we can‚Äôt generate all possible random samples.\n",
    "- We side with the null only if the observed statistic is **consistent** with the empirical distribution of the test statistic.\n",
    "- **Question:** is there a formal definition for what we mean by \"consistent\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Midterm scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The problem\n",
    "\n",
    "- Consider a large Biology course divided into 12 discussion sections. \n",
    "- Each student is in exactly one discussion section.\n",
    "- TAs lead the sections.\n",
    "- After the midterm exam, students in Section 3 notice that the average score in their section is lower than in others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The TA's defense\n",
    "\n",
    "- **The TA's position (Null Hypothesis)**: It's chance. If students were divided into sections randomly, we'd probably see at least one section with a score this low.\n",
    "- **Alternative Hypothesis**: No, the average score is too low. Randomness is not the only reason for the low scores.\n",
    "- Let's perform a hypothesis test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "scores = bpd.read_csv('data/scores_by_section.csv')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.groupby('Section').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average midterm score per section\n",
    "scores.groupby('Section').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What are the observed characteristics of section 3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_size = scores.groupby('Section').count().get('Midterm').loc[3]\n",
    "observed_avg = scores.groupby('Section').mean().get('Midterm').loc[3]\n",
    "print(f'Section 3 had {section_size} students and an average midterm score of {observed_avg}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simulating under the null hypothesis\n",
    "- Model: There is no significant difference between the exam scores in different sections, and observed differences are purely due to chance.\n",
    "    - To simulate: sample 27 students uniformly at random without replacement from the class.\n",
    "- Test statistic: The average midterm score of a section.\n",
    "    - The observed statistic is the average midterm score of Section 3 (13.6666)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.sample(int(section_size), replace=False).get('Midterm').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = np.array([])\n",
    "repetitions = 10000\n",
    "for i in np.arange(repetitions):\n",
    "    random_sample = scores.sample(int(section_size), replace=False)\n",
    "    new_average = random_sample.get('Midterm').mean()\n",
    "    averages = np.append(averages, new_average)\n",
    "    \n",
    "averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd.DataFrame().assign(RandomSampleAverage=averages).plot(kind='hist', bins=25, ec='w', figsize=(10, 5))\n",
    "plt.axvline(observed_avg, color='red', label='observed statistic')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What's the verdict? ü§î\n",
    "- This is not as obvious as in previous examples, where it was clear whether the observed statistic was consistent with the empirical distribution of the test statistic.\n",
    "- We need a precise way of capturing the uncertainty of the conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistical significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Question:** What is the probability that under the null hypothesis, a result *at least* as extreme as our observation occurs?\n",
    "- In this example, what is the probability that under the null hypothesis, a section of 27 students has an average exam score of 13.66 or lower?\n",
    "- This quantity is called a **p-value**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(averages <= observed_avg) / repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd.DataFrame().assign(RandomSampleAverage=averages).plot(kind='hist', bins=25, ec='w', figsize=(10, 5))\n",
    "plt.axvline(observed_avg, color='red', label='observed statistic')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Definition of the p-value\n",
    "\n",
    "- The p-value is **the probability, under the null hypothesis, that the test statistic is equal to the value that was observed in the data or is even further in the direction of the alternative**.\n",
    "- Its formal name is the _observed significance level_.\n",
    "- In the previous visualization, it is the area to the left of the red line (i.e. the area in the left tail, starting at the observed statistic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conventions about inconsistency\n",
    "\n",
    "- If the p-value is sufficiently large, we say the data is **consistent** with the null hypothesis and so we \"**fail to reject the null hypothesis**\".\n",
    "    - We never say that we \"accept\" the null hypothesis!\n",
    "- If the p-value is below some cutoff, we say it is **inconsistent** with the null hypothesis, and we **\"reject the null hypothesis\"**.\n",
    "    - p-values correspond to the \"tail areas\" of a histogram, starting at the observed statistic.\n",
    "    - If a p-value is less than 0.05, the result is said to be \"statistically significant\".\n",
    "    - If a p-value is less than 0.01, the result is said to be \"highly statistically significant\".\n",
    "    - These conventions are historical!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Error probabilities\n",
    "\n",
    "The cutoff for the p-value is an error probability. If:\n",
    "\n",
    "- your cutoff is 0.05, and\n",
    "- the null hypothesis happens to be true\n",
    "\n",
    "then there is about a 0.05 chance that your test will (incorrectly) reject the null hypothesis.\n",
    "\n",
    "- In other words, if the same TA teaches 20 discussion sections for the same course, they should expect to see students with a \"statistically significantly low\" average in one of those sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comparing distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Jury Selection in Alameda County\n",
    "\n",
    "<br>\n",
    "\n",
    "<center><img src='data/aclu.png' width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Jury panels\n",
    "\n",
    "$$\\text{eligible population} \\rightarrow \\text{list of eligible jurors} \\rightarrow \\text{jury panel} \\rightarrow \\text{actual jury}$$\n",
    "\n",
    "Section 197 of California's Code of Civil Procedure says, \n",
    "> \"All persons selected for jury service shall be selected at random, from a source or sources inclusive of a representative cross section of the population of the area served by the court.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ACLU study:\n",
    "- The ACLU (American Civil Liberties Union) of Northern California studied the ethnic composition of jury panels in 11 felony trials in Alameda County between 2009 and 2010.\n",
    "    - [Here's a link](https://www.aclunc.org/sites/default/files/racial_and_ethnic_disparities_in_alameda_county_jury_pools.pdf) to the study.\n",
    "- 1453 people reported for jury duty in total (we will call them \"panelists\").\n",
    "- The following DataFrame shows the distribution in ethnicities for both the eligible population and for the panelists who were studied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jury = bpd.DataFrame().assign(\n",
    "    Ethnicity=['Asian', 'Black', 'Latino', 'White', 'Other'],\n",
    "    Eligible=[0.15, 0.18, 0.12, 0.54, 0.01],\n",
    "    Panels=[0.26, 0.08, 0.08, 0.54, 0.04]\n",
    ")\n",
    "jury"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What do you notice? ü§î"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Are the differences in representation meaningful?\n",
    "- Model: Panelists were selected at random from the eligible population.\n",
    "    - Alternative viewpoint: no, they weren't.\n",
    "- Observation: 1453 panelists and the distribution of their ethnicities.\n",
    "- Test statistic: ???\n",
    "    - How do we deal with multiple categories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "jury.plot(kind='barh', x='Ethnicity');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The distance between two distributions\n",
    "- Panelists are categorized into one of 5 ethnicities.\n",
    "- The distribution of ethnicities is **categorical**.\n",
    "- To see whether the the distribution of ethnicities for the panelists is similar to that of the eligible population, we have to measure the distance between two categorical distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The distance between two distributions\n",
    "- Let's start by considering the difference in proportions for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_diffs = jury.assign(Difference=(jury.get('Panels') - jury.get('Eligible')))\n",
    "with_diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that if we sum these differences, the result is 0.\n",
    "- So that the positive and negative differences don't \"cancel\", we can take the absolute value of these differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with_abs_diffs = with_diffs.assign(AbsoluteDifference=np.abs(with_diffs.get('Difference')))\n",
    "with_abs_diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Statistic: Total Variation Distance\n",
    "- The **Total Variation Distance (TVD)** of two categorical distributions is **the sum of the absolute differences of their proportions, all divided by 2**.\n",
    "    - We divide by 2 so that, for example, the distribution [0.51, 0.49] is 0.01 off from [0.50, 0.50].\n",
    "    - This way, TVD quantifies the **total overrepresentation** across all categories.\n",
    "    - It would also be valid not to divide by 2. We just wouldn't call that statistic TVD anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_abs_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_abs_diffs.get('AbsoluteDifference').sum() / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discussion Question\n",
    "\n",
    "What is the TVD between the distributions of class standing in DSC 10 and DSC 40A?\n",
    "\n",
    "| **Class Standing** | **DSC 10** | **DSC 40A** |\n",
    "| --- | --- | --- |\n",
    "| Freshman | 0.45 | 0.15 |\n",
    "| Sophomore | 0.35 | 0.35 |\n",
    "| Junior | 0.15 | 0.35 |\n",
    "| Senior+ | 0.05 | 0.15 |\n",
    "\n",
    "- A. 0.2\n",
    "- B. 0.3\n",
    "- C. 0.5\n",
    "- D. 0.6\n",
    "- E. None of the above\n",
    "\n",
    "### To answer, go to [menti.com](https://menti.com) and enter the code 4235 1662."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Statistic: Total Variation Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_variation_distance(dist1, dist2):\n",
    "    '''Computes the TVD between two categorical distributions, \n",
    "       assuming the categories appear in the same order.'''\n",
    "    return np.abs((dist1 - dist2)).sum() / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the TVD between the distribution of ethnicities in the eligible population\n",
    "# and the distribution of ethnicities in the observed panelists\n",
    "\n",
    "total_variation_distance(jury.get('Eligible'), jury.get('Panels'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The closer the TVD is to 0, the closer the two distributions are to one another.\n",
    "- But is 0.14 a very small value? A typical value? A very large value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simulate drawing jury panels\n",
    "- Model: Panels are drawn at from the eligible population.\n",
    "- Statistic: TVD between the random panel's ethnicity distribution and the eligible population's ethnicity distribution.\n",
    "- Repeat many times to generate many TVDs, and see where the TVD of the observed panelists lies.\n",
    "\n",
    "_Note: `np.random.multinomial` creates samples drawn with replacement, even though real jury panels would be drawn without replacement. However, when the sample size is small relative to the population, the resulting distributions will be roughly the same whether we sample with or without replacement._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "eligible = jury.get('Eligible')\n",
    "sample_distribution = np.random.multinomial(1453, eligible) / 1453 \n",
    "sample_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panels_and_sample = jury.assign(RandomSample=sample_distribution) \n",
    "panels_and_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panels_and_sample.plot(kind='barh', x='Ethnicity');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_variation_distance(panels_and_sample.get('RandomSample'), eligible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Repeating the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvds = np.array([])\n",
    "repetitions = 10000\n",
    "for i in np.arange(repetitions):\n",
    "    sample_distribution = np.random.multinomial(1453, eligible) / 1453\n",
    "    new_tvd = total_variation_distance(sample_distribution, eligible)\n",
    "    tvds = np.append(tvds, new_tvd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_tvd = total_variation_distance(jury.get('Panels'), eligible)\n",
    "\n",
    "bpd.DataFrame().assign(tvds=tvds).plot(kind='hist', density=True, bins=20, ec='w', figsize=(10, 5))\n",
    "plt.axvline(observed_tvd, color='red', label='observed statistic')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Calculating the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(tvds >= observed_tvd) / repetitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Are the jury panels representative?\n",
    "- Likely not! The distributions of ethnicities in our random samples are not like the distribution of ethnicities in our observed panelists.\n",
    "- This doesn't say *why* the distributions are different!\n",
    "    - Juries are drawn from voter registration lists and DMV records. Certain populations are less likely to be registered to vote or have a driver's license due to historical biases.\n",
    "    - The county rarely enacts penalties for those who don't appear for jury duty; certain populations are less likely to be able to miss work to appear for jury duty.\n",
    "    - [See the report](https://www.aclunc.org/sites/default/files/racial_and_ethnic_disparities_in_alameda_county_jury_pools.pdf) for more reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary of the method\n",
    "\n",
    "To assess whether a sample was drawn randomly from a known categorical distribution:\n",
    "- Use TVD as the test statistic because it measures the distance between categorical distributions.\n",
    "- Sample at random from the population and compute the TVD between the random sample and the population; repeat numerous times.\n",
    "- Compare:\n",
    "    - The empirical distribution of simulated TVDs, and\n",
    "    - The actual TVD from the sample in the study.\n",
    "- See Question 6 on Homework 5 for an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- A hypothesis test helps us decide between two hypotheses ‚Äì a \"null\" hypothesis and an \"alternative\" hypothesis. Framework:\n",
    "    - Collect some real world data. (e.g. 1453 panelists, students in a real Biology course).\n",
    "    - Specify a null and alternative hypothesis.\n",
    "    - Specify a test statistic.\n",
    "    - Simulate data under the assumption the null hypothesis is true and compute the test statistic on each one. This creates an empirical distribution of the test statistic.\n",
    "    - Check if the observed statistic is consistent with the empirical distribution of the test statistic.\n",
    "- To conclude whether an observed statistic is consistent with an empirical distribution of that test statistic, we compute a p-value, which is the probability, under the null hypothesis, that the test statistic is equal to the observed statistic or is even further in the direction of the alternate hypothesis.\n",
    "    - There are conventional cutoffs for significance. 0.05 is the most common.\n",
    "- The total variation distance is a test statistic that measures the difference between two categorical distributions.\n",
    "- **Next time**: How do we test whether two samples are from the same numerical distribution?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
